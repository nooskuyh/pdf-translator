D. 크로이츠베르거 외: 머신러닝 운영(MLOps): 개요, 정의, 그리고 아키텍처

코드 예시로는 Bitbucket, GitLab, GitHub, Gitea 등이 있습니다. C3 워크플로 오케스트레이션 컴포넌트는 DAGs를 통해 ML 워크플로의 작업을 조율합니다. 이러한 그래프는 워크플로의 각 단계의 실행 순서와 아티팩트 사용을 나타냅니다. 워크플로는 예를 들어, 데이터 추출, 모델 훈련, 추론 등과 같은 프로세스 단계에서 패키지 코드를 사용합니다. Apache Airflow, Kubeflow Pipelines, Watson Studio Pipelines, Luigi 등이 예시입니다. CI/CD 도구는 특정 작업을 순차적으로 트리거하는 데 사용할 수 있지만, 데이터 엔지니어링 및 ML 파이프라인 작업의 복잡성 증대로 인해 워크플로나 작업 조율에 특화된 도구가 필요합니다. 이러한 도구는 복잡한 작업 체인을 관리하기 쉽게 해줍니다. 

C4 피처 스토어 시스템은 일반적으로 사용되는 피처의 중앙 저장을 보장합니다. 오프라인 및 온라인 피처 스토어로 구성되어 있습니다. Google Feast, AWS Feature Store, Tecton.ai 등이 예시입니다. 대부분의 데이터는 ML 모델 훈련에 사용됩니다. 확장성은 일반적으로 클라우드 인프라를 통해 실현됩니다. 

C5 모델 훈련 인프라는 CPU, RAM, GPU 등의 컴퓨팅 자원을 제공합니다. 분산 또는 비분산 인프라를 제공하며, 대개 확장 가능한 분산 인프라가 권장됩니다. 로컬 머신 또는 클라우드 컴퓨팅, 분산 계산 등이 예로 들 수 있습니다.

C6 모델 레지스트리는 훈련된 ML 모델과 메타데이터를 중앙에 저장합니다. 주요 기능으로는 ML 아티팩트 및 메타데이터 저장이 있으며, MLflow, AWS SageMaker Model Registry 등이 있습니다. 

C7 ML 메타데이터 스토어는 각 ML 워크플로 파이프라인 작업의 다양한 메타데이터를 기록합니다. Kubeflow Pipelines, AWS SageMaker Pipelines 등이 예시입니다. 

C8 모델 서빙 컴포넌트는 온라인 추론이나 대량의 입력 데이터를 사용하는 배치 추론 등 다양한 목적으로 구성할 수 있습니다. 예를 들어, Kubernetes와 Docker를 사용해 모델을 컨테이너화하고 Flask와 같은 웹 프레임워크를 활용할 수 있습니다. 실제 모델 배포는 실시간, 배치, 또는 서버리스 추론으로 분류됩니다. 

VOLUME 11, 2023
