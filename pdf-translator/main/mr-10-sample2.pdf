다음은 자연어 처리(NLP) 분야에서 노트북 기반 환경을 활용한 사례입니다. 감정 분석, 텍스트 요약, 명명된 엔터티 인식 등의 NLP 서비스를 제공하는 회사는 대량의 텍스트 데이터에 대한 머신러닝 실험을 Jupyter 노트북에서 수행할 수 있습니다. 데이터 과학자들은 데이터를 준비하고, 다양한 머신러닝 모델(e.g., 딥러닝 모델)을 학습, 평가, 최적화하며 결과를 테스트합니다. MLflow나 Neptune.AI 같은 솔루션을 사용해 메타데이터를 추적하고 결과 모델을 저장합니다.

자동화된 ML 워크플로 파이프라인의 관리에는 DevOps 엔지니어와 ML 엔지니어가 관여하며, 런타임 환경, 하드웨어 리소스 및 Kubernetes와 같은 프레임워크 관리를 맡습니다. 워크플로 오케스트레이션 컴포넌트는 작업들을 관리하며, 각 태스크는 이미지 레지스트리에서 아티팩트를 가져와 독립된 환경에서 실행됩니다. 이러한 과정에서 작업의 메타데이터가 수집됩니다.

자동화된 파이프라인에는 다음의 작업들이 포함됩니다: 
(18) 피처 스토어 시스템에서 버전 관리된 피처를 자동으로 가져오기, (19) 데이터 준비 및 검증 자동화, (20) 새로운 데이터에 대한 최종 모델 학습 자동화, (21) 모델 평가 및 하이퍼 파라미터 조정, 그리고 성능이 만족스러우면 학습이 중단됩니다. 
(22) 훈련된 모델은 모델 레지스트리에 저장됩니다. ML 메타데이터 스토어는 모델 학습 작업의 메타데이터를 기록합니다. 여기에는 모델의 계보(lineage)도 포함됩니다.

모델이 프로덕션 준비 상태가 되면 DevOps 또는 ML 엔지니어에게 전달됩니다. 이후 지속적 배포(CI/CD) 파이프라인이 시작되어 ML 모델과 코드가 프로덕션 환경에 설치됩니다.

모델 서빙 컴포넌트는 새로운 데이터에 대한 예측을 수행하며, 실시간 또는 배치 추론을 지원합니다. A/B 테스트는 서로 다른 모델을 비교하는 데 유용합니다. 예를 들어, 호텔 예약 취소 예측 시 두 가지 모델을 비교할 수 있습니다. ML 엔지니어는 서빙 인프라를 관리하며, 모니터링 컴포넌트의 성능을 실시간으로 관찰합니다. 성능이 기준 이하일 경우 피드백 루프를 통해 빠르게 정보를 전송하고, 지속적인 학습 및 개선이 이루어집니다. 피드백은 실험 단계에서 모델 개선에 활용됩니다. 개념 변화 감지와 같은 메커니즘은 실시간 애플리케이션에서 지속 학습을 가능하게 합니다.
